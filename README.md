
# NLP Topic Modeling Preprocessing Pipeline

This repository contains a robust and modular pipeline for **text preprocessing**, **topic modeling** with BERTopic, and **interactive result exploration** via a Streamlit dashboard.  
It is designed for high-throughput, reproducible experiments on raw text data (e.g., surveys, user feedback, or transcripts).

---

## ğŸ§° Features

- ğŸ“„ Preprocessing of raw textual data (cleaning, normalization, lemmatization, etc.)
- ğŸ” Topic modeling using BERTopic (with KMeans-based variants)
- ğŸ“ Fully automated file structure with time-stamped outputs
- ğŸ“Š Interactive dashboard for in-depth topic exploration
- ğŸ”§ Configurable pipeline via `config.json`
- âš™ï¸ Easily extendable and modular codebase
- âœ… MIT License â€” open to academic and commercial reuse

---

## ğŸš€ Usage

### 1. Setup

Clone the repository and install dependencies:

```bash
pip install -r requirements.txt
```

### 2. Configure your pipeline

```json
{
  "input_path": "input/my_data.csv",
  "output_dir": "results",
  "launch_dashboard": true
}
```

- `input_path`: path to your CSV file (must contain a `comment` column)
- `output_dir`: root folder where outputs will be saved
- `launch_dashboard`: if `true`, opens the Streamlit dashboard in your browser at the end of processing

---

### 3. Run the pipeline

```bash
python cli.py
```

This will:

- Clean your data
- Run BERTopic with multiple values of `k`
- Save results and visualizations
- Optionally launch the dashboard

---

## ğŸ“Š Dashboard Overview

If `launch_dashboard = true`, the pipeline ends by launching a **Streamlit dashboard** that provides:

### Sidebar

- Selection of results folder
- Dynamic dropdown to select number of topics (`k`)
- Stop button to exit cleanly

### Main Interface

- ğŸ“Œ Pipeline summary: number of documents, topics, unassigned documents
- ğŸ” Search: filter documents by keyword
- ğŸ§  Topic explorer: view documents assigned to a given topic
- ğŸ“ˆ Topic summary table
- ğŸŒ Interactive visualizations:
  - `topics_visualization.html` (global clustering)
  - `IDM_kX.html` (specific to selected `k`)

---

## ğŸ“ Output Structure

After each run, a new subfolder is created under `results/YYYY-MM-DD/HH-MM-SS/` containing:

```
results/
â””â”€â”€ 2025-07-30/
    â””â”€â”€ 15-42-10/
        â”œâ”€â”€ cleaned/
        â”‚   â””â”€â”€ cleaned_data.csv
        â”œâ”€â”€ topics/
        â”‚   â”œâ”€â”€ topics.csv
        â”‚   â”œâ”€â”€ summary_topics.csv
        â”‚   â””â”€â”€ topics_visualization.html
        â”œâ”€â”€ analytics/
        â”‚   â””â”€â”€ k10/
        â”‚       â”œâ”€â”€ summary_topics.csv
        â”‚       â””â”€â”€ IDM_k10.html
        â””â”€â”€ config_used.json
```

---

## ğŸ§ª Requirements

- Python â‰¥ 3.8
- `bertopic`, `sentence-transformers`, `streamlit`, `scikit-learn`, `pandas`, `umap-learn`, `matplotlib`

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” you are free to use, modify, and redistribute it for academic and commercial purposes. See [`LICENSE`](LICENSE) for details.

---

## ğŸ¤ Contributions

Contributions are welcome. Please submit pull requests with detailed commit messages and test your changes locally.
